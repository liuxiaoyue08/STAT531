---
title: "STATS 531 HW3"
author: "Xiaoyue Liu    UMID:28589009    xiaoyliu@umich.edu"
date: "February 2, 2016"
output: html_document
---

\newcommand\prob{\mathbb{P}}
\newcommand\E{\mathbb{E}}
\newcommand\var{\mathrm{Var}}
\newcommand\cov{\mathrm{Cov}}
\newcommand\loglik{\ell}
\newcommand\R{\mathbb{R}}
\newcommand\data[1]{#1^*}
\newcommand\params{\, ; \,}
\newcommand\transpose{\scriptsize{T}}
\newcommand\eqspace{\quad\quad\quad}
\newcommand\lik{\mathscr{L}}
\newcommand\loglik{\ell}
\newcommand\profileloglik[1]{\ell^\mathrm{profile}_#1}
\newcommand\ar{\phi}
\newcommand\ma{\psi}

-------------------

------------------

**<big>1.Read in the data</big>**

* We mainly work on the Ann Arbor January Low temperature time series.In the data set we have 12 variables, and the low temperature time series are in the Low column.

* There are some missing values within the Low variable. Here we delete them before the analysis. 

```{r read_data}
x <- read.table(file="http://ionides.github.io/531w16/intro/ann_arbor_weather.csv",header=TRUE)
x1 <- na.omit(x)
head(x1)
```

-------------------

------------------

**<big>2.Brief summary of the data</big>**

* First let's have a look at the time series of the low temperature. 
The low temperature range from -22 to 19, with a mean -2.833 and a median -3.000.
The black line shows how the low temperature in January changed from 1900 to 2014, and the blue line represents the mean for this time series.

```{r summary_plot, echo = F}
summary(x1$Low)
plot(Low~Year,data=x1,type="l")
lines(x = x1$Year, y = rep(mean(x1$Low, na.rm = T), length(x1$Year)), col = "blue", lwd = 1.5)
```

* The mean function is defined as follows, which we also call as "trend":
$$ \mu_n = \E[X_n] = \int_{-\infty}^\infty x_n \, f^{}_{X_n}(x_n)\, dx_n$$
for $n\in 1:N$. 

* From the plot above we can not see the presence of a significant trend in the Low Temperature. And by the description of this homework task, we can do the analysis with an assumption that there is no trend embedded in this time series.

* In summary, we can try to fit a mean stationary model for this time series. 

-------------------

------------------

**<big>3.Fitting an ARMA model</big>**

* Let's start by fitting a stationary ARMA$(p,q)$ model under the null hypothesis that there is no trend. This hypothesis, which asserts that nothing has substantially changed in this system over the last 150 years, is not entirely unreasonable from looking at the data.


* We seek to fit a stationary Gaussian ARMA(p,q) model with parameter vector $\theta=(\ar_{1:p},\ma_{1:q},\mu,\sigma^2)$ given by
$$ \ar(B)(X_n-\mu) = \ma(B) \epsilon_n,$$
where 
$$\begin{eqnarray}
\mu &=& \E[X_n]
\\
\ar(x)&=&1-\ar_1 x-\dots -\ar_px^p,
\\ 
\ma(x)&=&1+\ma_1 x+\dots +\ma_qx^q, 
\\
\epsilon_n&\sim&\mathrm{ iid }\, N[0,\sigma^2].
\end{eqnarray}$$


* We need to decide where to start in terms of values of $p$ and $q$. Viewed as a way to select a model with reasonable predictive skill from a range of possibilities. 
* Akaike's information criterion **AIC** is given by $$ AIC = -2 \times \loglik(\data{\theta}) + 2D$$ 
* AIC is often useful. Let's tabulate some AIC values for a range of different choices of $p$ and $q$.

```{r AIC, message = FALSE, warning = FALSE, echo = FALSE}
aic_table <- function(data,P,Q){
  table <- matrix(NA,(P+1),(Q+1))
  for(p in 0:P) {
    for(q in 0:Q) {
       table[p+1,q+1] <- arima(data,order=c(p,0,q))$aic
    }
  }
  dimnames(table) <- list(paste("<b> AR",0:P, "</b>", sep=""),paste("MA",0:Q,sep=""))
  table
}
low_aic_table <- aic_table(x$Low,4,5)
require(knitr)
kable(low_aic_table,digits=2)
```

* We are invited to select the model with the lowest AIC score. Let's see which is the smallest AIC in the table:

```{r smallest_AIC, echo = FALSE}
round(min(low_aic_table),2)
```

* From the table we can find that the smallest AIC corresponds to the ARMA(0,0) model, which responds the white noise model:  $$X_n-\mu = \epsilon_n$$ (Here we suppose $\epsilon_n$ 
is the Gaussian white noise where $\epsilon_{1:N} \sim \mbox{IID } N[0,\sigma^2]$)

* Fit the data with the suggested ARMA(0,0) model:

```{r arma_model, echo=FALSE}
low_arma<-arima(x1$Low,order=c(0,0,0))
low_arma
```

* We find $$\mu = 2.8333$$, so that the data can be modeled by:

$$X_n+2.8333=\epsilon_n$$


* However, it is still unclear whether white noise is the true model as AIC is just a way to select a reasonable model.

-------------------

------------------

**<big>4.Compare data with fitted model</big>**

* First we can compare the data with normal distribution to test if a Gaussian white noise model fits. To achieve this goal we can use the histogram.

```{r histogram, echo = FALSE}
hist(x1$Low, probability = T, main = "Histogram of Low Temperature in January", ylim = c(0,0.06), xlab = "Low Temperature")
```

* The distribution of low temperature in January looks similar to normal. To see further in detail, we can test whether the distribution of low temperature in January follows a normal distribution by QQ-plot

```{r qqplot, echo=FALSE}
plot(Low~Year,data = x1, xlab = 'Year',ylab='Low Temperature in January')
abline(h=0,col='red')
qqnorm(x1$Low)
qqline(x1$Low)
```

* From QQ-plot we can see that the low temperature in January follows a normal distribution, which means the white noise model is a good choice for this data set.

* We can also compare the autocovariance of the low temperature time series and the white noise model.

* The properties of white noise are:
$$\begin{eqnarray}
\E[\epsilon_n]&=& 0 \\
\cov(\epsilon_m,\epsilon_n) &=& \left\{\begin{array}{ll}
  \sigma^2, & \mbox{if $m=n$} \\
   0, & \mbox{if $m\neq n$} \end{array}\right. ,
\end{eqnarray}$$

* The Autocovraiance for white noise model is: 
$$ \begin{eqnarray} \gamma_{h} = \left\{ \begin{array}{ll} \sigma^2 & \textrm{if $h=0$}\\ 0 & \textrm{if $h\neq0$}\end{array} \right. \end{eqnarray} $$

* Let's compute the acf and variance of the low temperature
```{r acfs}
acf(x1$Low, type = "covariance", plot = F)
var(x1$Low)
```

* We can see that the acf of the low temperature is 53.367, which is close to the variance of the low temperature, which is 53.83923. It means that the white noise model fits the low temperature data really well. 

* Here is the acf of the data from the time series:
```{r acf_data}
summary(acf(x1$Low)$acf)
```

* Then we simulate a time series with 115 time points for the ARMA(0,0) model (the white noise model) and get its acf:
```{r acf_model}
set.seed(123456789)
ARMA_0_0 <- arima.sim(list(c(0,0,0)),115)
summary(acf(ARMA_0_0)$acf)
```

* We can see that the two acf plots are similar. Again it shows the white noise model does fit the data quite well.

-------------------

------------------

**<big>5.Summary</big>**

* We find ARMA(0,0)(Gaussian white noise) model fits the Ann Arbor January Low temperature time series. We compute the autocovariance of the data and compare the data with a normal distribution. All of these results suggest that ARMA(0,0)(Gaussian white noise) model is a good fit for the data.

* As white noise model fits the data well, it means that there's no pattern, just random variation in the low temperature in January for Ann Arbor, showing that we can not predict next year's low temperature based on data from previous years. Maybe one year is too long for predicting the temperature. Last year(2014) it was quite cold in January and there was lot of snow, however this year it is too warm for Michigan winter, resulting in little snow and difficulty for snow resorts to make snow.


